{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.document_loaders import OnlinePDFLoader\n",
    "from langchain.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain.indexes.vectorstore import VectorstoreIndexCreator\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from typing_extensions import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"gpt-4.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\n",
    "for page in reader.pages:\n",
    "    raw_text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPT-4 Technical Report\\nOpenAI\\x03'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=300,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GPT-4 Technical Report\\nOpenAI\\x03\\nAbstract\\nWe report the development of GPT-4, a large-scale, multimodal model which can\\naccept image and text inputs and produce text outputs. While less capable than\\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance\\non various professional and academic benchmarks, including passing a simulated\\nbar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-\\nbased model pre-trained to predict the next token in a document. The post-training\\nalignment process results in improved performance on measures of factuality and\\nadherence to desired behavior. A core component of this project was developing\\ninfrastructure and optimization methods that behave predictably across a wide\\nrange of scales. This allowed us to accurately predict some aspects of GPT-4’s\\nperformance based on models trained with no more than 1/1,000th the compute of\\nGPT-4.\\n1 Introduction',\n",
       " 'infrastructure and optimization methods that behave predictably across a wide\\nrange of scales. This allowed us to accurately predict some aspects of GPT-4’s\\nperformance based on models trained with no more than 1/1,000th the compute of\\nGPT-4.\\n1 Introduction\\nThis technical report presents GPT-4, a large multimodal model capable of processing image and\\ntext inputs and producing text outputs. Such models are an important area of study as they have the\\npotential to be used in a wide range of applications, such as dialogue systems, text summarization,\\nand machine translation. As such, they have been the subject of substantial interest and progress in\\nrecent years [1–34].\\nOne of the main goals of developing such models is to improve their ability to understand and generate\\nnatural language text, particularly in more complex and nuanced scenarios. To test its capabilities\\nin such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans. In']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings()\n",
    "search = FAISS.from_texts(text, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"gemma:2b\")\n",
    "chain = load_qa_chain(llm=llm, chain_type=\"refine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"why is this report important?\"\n",
    "pdf = search.similarity_search(query) \n",
    "chain.run(pdf, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = OnlinePDFLoader(\"abc.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()\n",
    "embeddings = OllamaEmbeddings()\n",
    "index = VectorstoreIndexCreator().from_loaders([loader], embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"why is this report important?\"\n",
    "index.query(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
